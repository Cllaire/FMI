{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[ProbProg] Homework 2 - Ana Cristina Rogoz",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tFSFxh-aPN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pymc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCm0dAQYor1P",
        "colab_type": "code",
        "outputId": "723b25b6-885f-451c-c059-b853bafc95bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "source": [
        "# !pip install tensorflow==1.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9f/be0165c6eefd841e6928e54d3d083fa174f92d640fdc52f73a33dc9c54d1/tensorflow-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (41.2MB)\n",
            "\u001b[K     |████████████████████████████████| 41.2MB 73kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4) (1.17.5)\n",
            "Collecting enum34>=1.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4) (1.12.0)\n",
            "Collecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/9f/5845c18f9df5e7ea638ecf3a272238f0e7671e454faa396b5188c6e6fc0a/tensorflow_tensorboard-0.4.0-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4) (0.33.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.4) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4) (0.16.0)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 63.5MB/s \n",
            "\u001b[?25hCollecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4) (3.1.1)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107221 sha256=897b5249f3b0ea46c2e78a86ee6c8a9781b29a2ae1811107452cd67c56f804d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement tensorflow>=1.5.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: enum34, html5lib, bleach, tensorflow-tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.0\n",
            "    Uninstalling bleach-3.1.0:\n",
            "      Successfully uninstalled bleach-3.1.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNo_0tO-57JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install arviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0f6fu84Ha7C",
        "colab_type": "text"
      },
      "source": [
        "# Load all the imports!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hSBAWiEBVyf",
        "colab_type": "code",
        "outputId": "6977296f-7222-4e18-ac1c-c7fc5b402268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pymc3 as pm \n",
        "import tensorflow as tf\n",
        "import theano.tensor as T\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import KFold \n",
        " \n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tuUxCMYHfUS",
        "colab_type": "text"
      },
      "source": [
        "# Description of the dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRspmSbbHiOC",
        "colab_type": "text"
      },
      "source": [
        "The dataset used for this project is taken from Kaggle and is called “Mice Protein\n",
        "Expression”. This dataset contains 82 columns in total and 1080 samples. From those 82\n",
        "columns, 77 represent protein levels measured in the cerebral cortex from 8 classes of mice.\n",
        "There are considered other 4 features, which are: Genotype, Treatment, Behaviour, Class\n",
        "and Mice Id. There are a total of 72 mice (38 control mice and 34 trisomic mice i.e. with\n",
        "Down Syndrome). For each mouse, there have been made 15 measurements (thus 1080\n",
        "samples - 570 for the control mice and 510 for the trisomic mice). For this problem, the\n",
        "target/label we are trying to predict is the class for each mice. There are 8 possible classes\n",
        "available, based on three characteristics: control mice or trisomic mice, stimulated or not\n",
        "to learn, injected with memantine or saline (where memantine is a drug meant for helping\n",
        "trisomic mice to recover their ability to learn and saline is used as a placebo). These classes\n",
        "are encoded in the following manner in the dataset: x − Y Z − w where:\n",
        "\n",
        "* x can be either c or t (control or trisomic)\n",
        "* XY can be either CS or SC (context-shock or not i.e. stimulated to learn or not) \n",
        "* w can be either m or s (memantine or saline) \n",
        "\n",
        "Other observations about this dataset:\n",
        "* Categorical features: Mouse ID, Genotype, Treatment, Behaviour, Class\n",
        "* Numerical features: all of the other 77 protein columns (most of them containing NaN\n",
        "values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jIzj7_r0QPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('Data_Cortex_Nuclear.csv', delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lpiN9zHITlm",
        "colab_type": "text"
      },
      "source": [
        "For this step, I’ve done a couple of things. Firstly, I’ve replaced all the NaN values for\n",
        "each protein with the corresponding mean value based on all the values for the same class as the sample. Secondly, I’ve dropped three columns (Genotype, Treatment and Behaviour)\n",
        "that were actually composing the class value, since if those three were left inside that dataset,\n",
        "the target label (class) could be directly learned by using only those three features and\n",
        "ignoring all the other protein values, achieving 100% accuracy. Also, I’ve dropped the mice\n",
        "id column, since it shouldn’t be correlated in any manner with the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_27Jcr1kvS2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['Genotype'] = pd.factorize(dataset['Genotype'])[0]\n",
        "dataset['Treatment'] = pd.factorize(dataset['Treatment'])[0]\n",
        "dataset['Behavior'] = pd.factorize(dataset['Behavior'])[0]\n",
        "dataset['class'] = pd.factorize(dataset['class'])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlW8bpKfv_tw",
        "colab_type": "code",
        "outputId": "c659d4fd-3b9b-4423-ea93-7f61a94c3f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "dataset = dataset.drop(['MouseID'], axis=1)\n",
        "dataset = dataset.drop(['Genotype'], axis=1)\n",
        "dataset = dataset.drop(['Treatment'], axis=1)\n",
        "dataset = dataset.drop(['Behavior'], axis=1)\n",
        "print (dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      DYRK1A_N   ITSN1_N    BDNF_N  ...  H3MeK4_N    CaNA_N  class\n",
            "0     0.503644  0.747193  0.430175  ...  0.128186  1.675652      0\n",
            "1     0.514617  0.689064  0.411770  ...  0.131119  1.743610      0\n",
            "2     0.509183  0.730247  0.418309  ...  0.127431  1.926427      0\n",
            "3     0.442107  0.617076  0.358626  ...  0.146901  1.700563      0\n",
            "4     0.434940  0.617430  0.358802  ...  0.148380  1.839730      0\n",
            "...        ...       ...       ...  ...       ...       ...    ...\n",
            "1075  0.254860  0.463591  0.254860  ...  0.328327  1.364823      7\n",
            "1076  0.272198  0.474163  0.251638  ...  0.293435  1.364478      7\n",
            "1077  0.228700  0.395179  0.234118  ...  0.355213  1.430825      7\n",
            "1078  0.221242  0.412894  0.243974  ...  0.365353  1.404031      7\n",
            "1079  0.302626  0.461059  0.256564  ...  0.365278  1.370999      7\n",
            "\n",
            "[1080 rows x 78 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOHEVx82w7r5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "\n",
        "dictionary = set()\n",
        "for index, row in dataset.iterrows():\n",
        "  for column in dataset.columns:\n",
        "      if (math.isnan(row[column])):\n",
        "        dictionary.add(column)\n",
        "\n",
        "for protein in dictionary:\n",
        "  dataset[protein] = dataset.groupby(['class'])[protein].transform(lambda x: x.fillna(x.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdUnZxJe_KvE",
        "colab_type": "text"
      },
      "source": [
        "# Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZuVy_R7IlnF",
        "colab_type": "text"
      },
      "source": [
        "For the binary classification task, I kept only the first two classes (from a total of eight possible ones) and scaled all the protein data features using the StandardScaler. Afterward, I've firstly written the classical version of the neural network (using sklearn), since it was training so much faster than the bayesian version and it was easier for me to find the best network architecture. \n",
        "In the end, I went for only one hidden layer with 8 units. Each input sample consists of 77 features, so for the first part (weights from input to layer 1), I've defined a variable with normal distribution (0, 1) of shape [77, 8], followed by another variable with normal distribution of shape [8, 1] for converting the outputs of the 8 units from hidden layer 1 to the output unit. I've used the hyperbolic tangent activation function for the hidden layer and sigmoid for the output unit. The actual label is modeled using a Bernoulli distribution in which the success probability is the output of the Bayesian NN (after sigmoid activation) and the data are the actual labels from the dataset.      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6fL6dlxeXsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_0 = dataset['class'] == 0\n",
        "class_1 = dataset['class'] == 1\n",
        "binary_dataset = dataset[class_0 | class_1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spXtPRFre0jZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binary_dataset_standardScaled = binary_dataset.copy()\n",
        "\n",
        "binary_dataset_standardScaled = binary_dataset_standardScaled.drop(['class'], axis=1)\n",
        "scaler = StandardScaler().fit(binary_dataset_standardScaled.values)\n",
        "binary_dataset_standardScaled = scaler.transform(binary_dataset_standardScaled.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt46DV4OhYWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_binary_dataset = binary_dataset['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JDL-Rm4WhJCm",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(binary_dataset_standardScaled,y_binary_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOAnv-T_QE9",
        "colab_type": "text"
      },
      "source": [
        "## Bayesian Neural Network - Pymc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znU9OB87nped",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_neural_network(input_data, output_data):\n",
        "  init_1 = np.random.randn(X_train.shape[1], 8).astype('float')\n",
        "  init_out = np.random.randn(8).astype('float')\n",
        "\n",
        "  with pm.Model() as neural_network:\n",
        "    input_data = pm.Data('input_data', X_train)\n",
        "    output_data = pm.Data('output_data', y_train)\n",
        "    weights_in_1 = pm.Normal('w_in_1', 0, sigma=1,\n",
        "                              shape=(X_train.shape[1], 8),\n",
        "                              testval=init_1)\n",
        "    weights_1_out = pm.Normal('w_1_out', 0, sigma=1,\n",
        "                              shape=(8,),\n",
        "                              testval=init_out)\n",
        "    act_1 = pm.math.tanh(pm.math.dot(input_data,\n",
        "                                      weights_in_1))\n",
        "    act_out = pm.math.sigmoid(pm.math.dot(act_1,\n",
        "                                          weights_1_out))\n",
        "    out = pm.Bernoulli('out',\n",
        "                        act_out,\n",
        "                        observed=output_data,\n",
        "                        total_size=y_train.shape[0]\n",
        "                      )\n",
        "  return neural_network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YebiZcCnq2py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neural_network = build_neural_network(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85p-r1eu1PZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with neural_network:\n",
        "    mcmc = pm.sample(draws=5000, tune=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8fG4zUJc9UN",
        "colab_type": "text"
      },
      "source": [
        "After fitting the Bayesian Neural Network on 5000 samples, I've drawn 100 more based on which there were done predictions for the training examples. On the training set, the model scored 0.96 accuracy, while on the test set the same model previously trained scored 0.97.\n",
        "(see figure 1 attached in the email). \n",
        "\n",
        "* The results are taken from running this code locally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTK_SuRC1RkL",
        "colab_type": "text"
      },
      "source": [
        "Predict labels for the training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKdo8pzR32Q_",
        "colab_type": "code",
        "outputId": "832835b1-b5b9-473d-f3d5-341aa1c98d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "predictions = pm.sample_ppc(mcmc, model=neural_network, samples=100) \n",
        "y_pred = predictions['out']\n",
        "\n",
        "print (\"[MCMC] Train set accuracy binary classification:\", accuracy_score(y_train, y_pred[99]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: sample_ppc() is deprecated.  Please use sample_posterior_predictive()\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "100%|██████████| 100/100 [00:01<00:00, 96.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MCMC] Train set accuracy binary classification: 0.9466666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-WKuLz9Q1Wnk"
      },
      "source": [
        "Predict labels for the testing set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g0oVpj40xw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pm.set_data(new_data={'input_data': X_test, 'output_data': y_test}, model=neural_network)\n",
        "predictions = pm.sample_ppc(mcmc, samples=100, model=neural_network)\n",
        "y_pred = predictions['out']\n",
        "\n",
        "print (\"[MCMC] Test set accuracy binary classification:\", accuracy_score(y_test, y_pred[99]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCR2zvk-NBWC",
        "colab_type": "text"
      },
      "source": [
        "### Sanity Check "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nu2-gOWjLAy",
        "colab_type": "text"
      },
      "source": [
        "The following plots represent the posterior values for the weights between the input layer and the hidden layer, and the hidden layer and the output unit. It can be noticed that those values finely represent the normal distribution that was implied at the beginning.\n",
        "\n",
        "Each color represents one of the units from the hidden layer, thus 8 colors. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS_gB8QSBKff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure() \n",
        "plt.hist(mcmc['w_in_1'][999][:][:])\n",
        "plt.title(\"Posteriori of w_in_1\")\n",
        "plt.savefig('Binary_w_in_1.png')\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(mcmc['w_1_out'][:][:])\n",
        "plt.title(\"Posteriori of w_1_out\")\n",
        "plt.savefig('Binary_w_1_out.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SqBTaLY1Qr9",
        "colab_type": "code",
        "outputId": "82e0788a-2204-49ca-8c85-9ac9d5467f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "pm.summary(mcmc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pymc3/stats.py:991: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
            "  axis=1, join_axes=[dforg.index])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>mc_error</th>\n",
              "      <th>hpd_2.5</th>\n",
              "      <th>hpd_97.5</th>\n",
              "      <th>n_eff</th>\n",
              "      <th>Rhat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_0</th>\n",
              "      <td>-0.002145</td>\n",
              "      <td>1.010474</td>\n",
              "      <td>0.011038</td>\n",
              "      <td>-1.906666</td>\n",
              "      <td>2.038097</td>\n",
              "      <td>9695.396050</td>\n",
              "      <td>1.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_1</th>\n",
              "      <td>-0.007687</td>\n",
              "      <td>1.009624</td>\n",
              "      <td>0.012803</td>\n",
              "      <td>-1.925829</td>\n",
              "      <td>1.979215</td>\n",
              "      <td>6539.120512</td>\n",
              "      <td>0.999900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_2</th>\n",
              "      <td>-0.006172</td>\n",
              "      <td>1.007659</td>\n",
              "      <td>0.011902</td>\n",
              "      <td>-2.006944</td>\n",
              "      <td>1.939658</td>\n",
              "      <td>9029.142984</td>\n",
              "      <td>0.999992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_3</th>\n",
              "      <td>0.012989</td>\n",
              "      <td>1.018552</td>\n",
              "      <td>0.011996</td>\n",
              "      <td>-1.875188</td>\n",
              "      <td>2.091175</td>\n",
              "      <td>6848.387082</td>\n",
              "      <td>0.999993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_4</th>\n",
              "      <td>0.018181</td>\n",
              "      <td>1.032996</td>\n",
              "      <td>0.012382</td>\n",
              "      <td>-2.081728</td>\n",
              "      <td>2.007508</td>\n",
              "      <td>7721.593058</td>\n",
              "      <td>0.999901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__3</th>\n",
              "      <td>0.052032</td>\n",
              "      <td>1.480189</td>\n",
              "      <td>0.041797</td>\n",
              "      <td>-2.985413</td>\n",
              "      <td>3.436330</td>\n",
              "      <td>1239.238526</td>\n",
              "      <td>0.999928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__4</th>\n",
              "      <td>-0.095907</td>\n",
              "      <td>1.533563</td>\n",
              "      <td>0.046863</td>\n",
              "      <td>-3.495857</td>\n",
              "      <td>3.105832</td>\n",
              "      <td>1121.965761</td>\n",
              "      <td>1.000045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__5</th>\n",
              "      <td>0.001783</td>\n",
              "      <td>1.500700</td>\n",
              "      <td>0.045702</td>\n",
              "      <td>-3.125904</td>\n",
              "      <td>3.454387</td>\n",
              "      <td>1097.558775</td>\n",
              "      <td>1.000896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__6</th>\n",
              "      <td>-0.035683</td>\n",
              "      <td>1.447664</td>\n",
              "      <td>0.038677</td>\n",
              "      <td>-3.295581</td>\n",
              "      <td>2.980715</td>\n",
              "      <td>1235.765159</td>\n",
              "      <td>1.000671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__7</th>\n",
              "      <td>-0.000904</td>\n",
              "      <td>1.504639</td>\n",
              "      <td>0.044430</td>\n",
              "      <td>-3.344437</td>\n",
              "      <td>3.189272</td>\n",
              "      <td>1157.208841</td>\n",
              "      <td>1.000090</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>624 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 mean        sd  mc_error  ...  hpd_97.5        n_eff      Rhat\n",
              "w_in_1__0_0 -0.002145  1.010474  0.011038  ...  2.038097  9695.396050  1.000022\n",
              "w_in_1__0_1 -0.007687  1.009624  0.012803  ...  1.979215  6539.120512  0.999900\n",
              "w_in_1__0_2 -0.006172  1.007659  0.011902  ...  1.939658  9029.142984  0.999992\n",
              "w_in_1__0_3  0.012989  1.018552  0.011996  ...  2.091175  6848.387082  0.999993\n",
              "w_in_1__0_4  0.018181  1.032996  0.012382  ...  2.007508  7721.593058  0.999901\n",
              "...               ...       ...       ...  ...       ...          ...       ...\n",
              "w_1_out__3   0.052032  1.480189  0.041797  ...  3.436330  1239.238526  0.999928\n",
              "w_1_out__4  -0.095907  1.533563  0.046863  ...  3.105832  1121.965761  1.000045\n",
              "w_1_out__5   0.001783  1.500700  0.045702  ...  3.454387  1097.558775  1.000896\n",
              "w_1_out__6  -0.035683  1.447664  0.038677  ...  2.980715  1235.765159  1.000671\n",
              "w_1_out__7  -0.000904  1.504639  0.044430  ...  3.189272  1157.208841  1.000090\n",
              "\n",
              "[624 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guN03E6X_Vs5",
        "colab_type": "text"
      },
      "source": [
        "## Multilayer Perceptron - Sklearn "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNMyYcIBnYl2",
        "colab_type": "text"
      },
      "source": [
        "For the classical neural network, I've implemented the same architecture (one hidden layer with 8 units, hyperbolic tangent activation function for the hidden layer outputs, and sigmoid for the output unit). \n",
        "I've kept the same dataset for both training and testing and got similar results to the Bayesian neural network (slightly better with sklearn):\n",
        "*  0.98 accuracy on the train set \n",
        "* 0.97 accuracy on the test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BAjvIojYhJC7",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9eec11a2-a3dd-4284-c728-401a4e2bf7ac",
        "id": "Y_q-0d3ihJDA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, input_dim = X_train.shape[1], activation='tanh'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OUgt-wwahJDF",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, epochs=20)\n",
        "print (\"[SKLEARN] Test set accuracy binary classification: \", model.evaluate(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThU4xMUo_NkT",
        "colab_type": "text"
      },
      "source": [
        "# Multiclass Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X3ywgP6pBL8",
        "colab_type": "text"
      },
      "source": [
        "For the multiclass task, I kept all the examples from the dataset and scaled them in the same manner as I did for the binary classification task. In this case, as well I've firstly written the classical version of the neural network (using sklearn), since it was training so much faster than the bayesian version and found an appropriate network architecture. \n",
        "Here as well we have one hidden layer with 8 units. Each input sample consists of 77 features, so for the first part (weights from input to layer 1) I've defined a variable with normal distribution (0, 1) of shape [77, 8], followed by another variable with normal distribution of shape [8, 8] for converting the outputs of the 8 units from hidden layer 1 to the 8 output units on which there is applied the softmax activation function. I've used the hyperbolic tangent activation function for the hidden layer and softmax for the output units since those values are treated as probability values in the Categorical container which returns an actual number (between 0 and 7)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4pBx4Q9Du-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasetStandardScaled = dataset.copy()\n",
        "\n",
        "datasetStandardScaled = datasetStandardScaled.drop(['class'], axis=1)\n",
        "scaler = StandardScaler().fit(datasetStandardScaled.values)\n",
        "features = scaler.transform(datasetStandardScaled.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-VJffrHX2hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_dataset = features\n",
        "y_dataset = dataset['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tub34W501L13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset,y_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IsT_kBSgBEvX"
      },
      "source": [
        "## Bayesian Neural Network - Pymc "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "unGsZs27WrVb",
        "colab": {}
      },
      "source": [
        "def build_neural_network(input_data, output_data):\n",
        "  init_1 = np.random.randn(X_train.shape[1], 8).astype('float')\n",
        "  init_out = np.random.randn(8, 8).astype('float')\n",
        "\n",
        "  with pm.Model() as neural_network:\n",
        "    input_data = pm.Data('input_data', X_train)\n",
        "    output_data = pm.Data('output_data', y_train)\n",
        "\n",
        "    weights_in_1 = pm.Normal('w_in_1', 0, sigma=1,\n",
        "                              shape=(X_train.shape[1], 8),\n",
        "                              testval=init_1)\n",
        "    weights_1_out = pm.Normal('w_1_out', 0, sigma=1,\n",
        "                              shape=(8, 8),\n",
        "                              testval=init_out)\n",
        "    act_1 = pm.math.tanh(pm.math.dot(input_data,\n",
        "                                      weights_in_1))\n",
        "    act_out = T.nnet.softmax(T.dot(act_1, weights_1_out))\n",
        "    out = pm.Categorical('out',\n",
        "                        p=act_out,\n",
        "                        observed=output_data,\n",
        "                        total_size=y_train.shape[0]\n",
        "                      )\n",
        "  return neural_network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NzvFzyxPWrVg",
        "colab": {}
      },
      "source": [
        "neural_network = build_neural_network(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1sCkDRViWrVh",
        "colab": {}
      },
      "source": [
        "with neural_network:\n",
        "    mcmc = pm.sample(draws=5000, tune=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxzHfdzfsLV9",
        "colab_type": "text"
      },
      "source": [
        "Similar to the binary classification task, after fitting the Bayesian Neural Network on 5000 samples, I've drawn 100 more based on which there were done predictions for the training examples. On the training set, the model scored 0.92 accuracy, while on the test set the same model previously trained scored 0.88.\n",
        "(see figure 2 attached in the email). \n",
        "\n",
        "* The results are taken from running this code locally (since on Colab it took much longer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-PXLkZqf996a"
      },
      "source": [
        "Predict labels for the training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vpJUyVVp996b",
        "colab": {}
      },
      "source": [
        "predictions = pm.sample_ppc(mcmc, model=neural_network, samples=100) \n",
        "y_pred = predictions['out']\n",
        "\n",
        "print (\"[MCMC] Train set accuracy multiclass classification:\", accuracy_score(y_train, y_pred[99]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8QF858Ao996f"
      },
      "source": [
        "Predict labels for the testing set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "805dd250-e663-4640-adb0-e72664d0d595",
        "id": "dJUYxtui996g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "pm.set_data(new_data={'input_data': X_test, 'output_data': y_test}, model=neural_network)\n",
        "predictions = pm.sample_ppc(mcmc, samples=100, model=neural_network)\n",
        "y_pred = predictions['out']\n",
        "\n",
        "print (\"[MCMC] Test set accuracy multiclass classification:\", accuracy_score(y_test, y_pred[99]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: sample_ppc() is deprecated.  Please use sample_posterior_predictive()\n",
            "  \n",
            "100%|██████████| 100/100 [00:00<00:00, 121.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MCMC] Test set accuracy binary classification: 0.9866666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mgb2Gv_R996j"
      },
      "source": [
        "### Sanity Check "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pB0_U7sslU3",
        "colab_type": "text"
      },
      "source": [
        "Similar to the binary case. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x4jWl5yV996k",
        "colab": {}
      },
      "source": [
        "plt.figure() \n",
        "plt.hist(mcmc['w_in_1'][999][:][:])\n",
        "plt.title(\"Posteriori of w_in_1\")\n",
        "plt.savefig('Multiclass_w_in_1.png')\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(mcmc['w_1_out'][999][:][:])\n",
        "plt.title(\"Posteriori of w_1_out\")\n",
        "plt.savefig('Multiclass_w_1_out.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "82e0788a-2204-49ca-8c85-9ac9d5467f96",
        "id": "cNo-Dp-d996o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "pm.summary(mcmc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pymc3/stats.py:991: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
            "  axis=1, join_axes=[dforg.index])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>mc_error</th>\n",
              "      <th>hpd_2.5</th>\n",
              "      <th>hpd_97.5</th>\n",
              "      <th>n_eff</th>\n",
              "      <th>Rhat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_0</th>\n",
              "      <td>-0.002145</td>\n",
              "      <td>1.010474</td>\n",
              "      <td>0.011038</td>\n",
              "      <td>-1.906666</td>\n",
              "      <td>2.038097</td>\n",
              "      <td>9695.396050</td>\n",
              "      <td>1.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_1</th>\n",
              "      <td>-0.007687</td>\n",
              "      <td>1.009624</td>\n",
              "      <td>0.012803</td>\n",
              "      <td>-1.925829</td>\n",
              "      <td>1.979215</td>\n",
              "      <td>6539.120512</td>\n",
              "      <td>0.999900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_2</th>\n",
              "      <td>-0.006172</td>\n",
              "      <td>1.007659</td>\n",
              "      <td>0.011902</td>\n",
              "      <td>-2.006944</td>\n",
              "      <td>1.939658</td>\n",
              "      <td>9029.142984</td>\n",
              "      <td>0.999992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_3</th>\n",
              "      <td>0.012989</td>\n",
              "      <td>1.018552</td>\n",
              "      <td>0.011996</td>\n",
              "      <td>-1.875188</td>\n",
              "      <td>2.091175</td>\n",
              "      <td>6848.387082</td>\n",
              "      <td>0.999993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_in_1__0_4</th>\n",
              "      <td>0.018181</td>\n",
              "      <td>1.032996</td>\n",
              "      <td>0.012382</td>\n",
              "      <td>-2.081728</td>\n",
              "      <td>2.007508</td>\n",
              "      <td>7721.593058</td>\n",
              "      <td>0.999901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__3</th>\n",
              "      <td>0.052032</td>\n",
              "      <td>1.480189</td>\n",
              "      <td>0.041797</td>\n",
              "      <td>-2.985413</td>\n",
              "      <td>3.436330</td>\n",
              "      <td>1239.238526</td>\n",
              "      <td>0.999928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__4</th>\n",
              "      <td>-0.095907</td>\n",
              "      <td>1.533563</td>\n",
              "      <td>0.046863</td>\n",
              "      <td>-3.495857</td>\n",
              "      <td>3.105832</td>\n",
              "      <td>1121.965761</td>\n",
              "      <td>1.000045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__5</th>\n",
              "      <td>0.001783</td>\n",
              "      <td>1.500700</td>\n",
              "      <td>0.045702</td>\n",
              "      <td>-3.125904</td>\n",
              "      <td>3.454387</td>\n",
              "      <td>1097.558775</td>\n",
              "      <td>1.000896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__6</th>\n",
              "      <td>-0.035683</td>\n",
              "      <td>1.447664</td>\n",
              "      <td>0.038677</td>\n",
              "      <td>-3.295581</td>\n",
              "      <td>2.980715</td>\n",
              "      <td>1235.765159</td>\n",
              "      <td>1.000671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_1_out__7</th>\n",
              "      <td>-0.000904</td>\n",
              "      <td>1.504639</td>\n",
              "      <td>0.044430</td>\n",
              "      <td>-3.344437</td>\n",
              "      <td>3.189272</td>\n",
              "      <td>1157.208841</td>\n",
              "      <td>1.000090</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>624 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 mean        sd  mc_error  ...  hpd_97.5        n_eff      Rhat\n",
              "w_in_1__0_0 -0.002145  1.010474  0.011038  ...  2.038097  9695.396050  1.000022\n",
              "w_in_1__0_1 -0.007687  1.009624  0.012803  ...  1.979215  6539.120512  0.999900\n",
              "w_in_1__0_2 -0.006172  1.007659  0.011902  ...  1.939658  9029.142984  0.999992\n",
              "w_in_1__0_3  0.012989  1.018552  0.011996  ...  2.091175  6848.387082  0.999993\n",
              "w_in_1__0_4  0.018181  1.032996  0.012382  ...  2.007508  7721.593058  0.999901\n",
              "...               ...       ...       ...  ...       ...          ...       ...\n",
              "w_1_out__3   0.052032  1.480189  0.041797  ...  3.436330  1239.238526  0.999928\n",
              "w_1_out__4  -0.095907  1.533563  0.046863  ...  3.105832  1121.965761  1.000045\n",
              "w_1_out__5   0.001783  1.500700  0.045702  ...  3.454387  1097.558775  1.000896\n",
              "w_1_out__6  -0.035683  1.447664  0.038677  ...  2.980715  1235.765159  1.000671\n",
              "w_1_out__7  -0.000904  1.504639  0.044430  ...  3.189272  1157.208841  1.000090\n",
              "\n",
              "[624 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ItuopASBEvb"
      },
      "source": [
        "## Multilayer Perceptron - Sklearn "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FhaGF8gst3Y",
        "colab_type": "text"
      },
      "source": [
        "Followed the same architecture (one hidden layer with 8 units and hyperbolic tangent activation function, followed by 8 output units on which there's applied softmax). \n",
        "\n",
        "Results show that this network scored 0.93 accuracy on both the training and the test set (see figure 3). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koCOH7xtHEDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nkuL3UjPegg",
        "colab_type": "code",
        "outputId": "4ad54003-150a-4fd7-b0ac-11807251f400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, input_dim = X_train.shape[1], activation='tanh'))\n",
        "model.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA_I5cY9RVIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, epochs=100)\n",
        "print (\"Multiclass accuracy sklearn: \", model.evaluate(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}