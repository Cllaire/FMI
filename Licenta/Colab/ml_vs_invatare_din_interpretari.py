# -*- coding: utf-8 -*-
"""ML vs. Invatare din Interpretari

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dHvP5jcfdyYTuxLEuHt3cZDtUF7IzXFJ
"""

from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import KFold 

import seaborn as sns; 
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import csv

"""# Setul de date"""

dataset = pd.read_csv('dataset.csv', delimiter=",")
dataset

"""Setul de date este alcătuit din **1000 de exemple** a câte **9 atribute**: rasa (Breed Name), greutatea (Weight), înălțimea (Height), longevitatea (Longevity), nivelul de energie (Energy Level),  atenția necesară (Attention Needs), lungimea blănii (Coat Length), sexul cățelului (Sex), numele stăpânului (Owner Name). 


1)  Breed Name: atribut categorial, poate lua 4 valori (Amstaff, Pug, Bloodhound, Jack Russel Terrier)
* Amstaff: 252 exemple
* Pug: 246
* Bloodhound: 250
* Jack Russel Terrier: 252

2) Weight: atribut numeric, variază între 4785.075 g și 52863.3533 g

3) Height: atribut numeric, variază între 23.186 cm și 67.8929 cm, poate conține valori NaN. 

4) Longevity: atribut numeric, variază între 6.0778 ani și 15.7658 ani

5) Energy Level: atribut categorial, poate lua 3 valori (low, med, high)
* low: 80 exemple
* med : 616 exemple
* high: 304 exemple

6) Attention Needs: atribut categorial, poate lua 3 valori (low, med, high)
* low: 23 exemple
* med: 273 exemple
* high: 704 exemple

7) Coat Length: atribut categorial, poate lua 2 valori(short, med) 
* short: 895 exemple
* med: 105 exemple

8) Sex: atribut categorial, poate lua 2 valori(female, male)
* female: 509 exemple
* male: 491exemple

9) Owner Name: atribut categorial, conține 511 valori distincte în setul de date

# Preprocesări

* Transformăm atributele categoriale în atribute numerice. 
* Înlocuim valorile NaN de pe coloana 'Height(cm)' în funcție de media înălțimii rasei din care face parte.
* Normalizăm atributele numerice ('Weight(g)','Height(cm)','Longevity(yrs)') folosind două metode: StandardScaler si MinMaxScaler
* Calculăm corelația dintre Breed Name(ceea ce vrem să prezicem) și toate celelalte atribute pentru a decide care sunt cele mai relevante pentru problema data.

## Asignăm fiecarei coloane de atribute categorial valori numerice.
"""

dataset['Breed Name'] = pd.factorize(dataset['Breed Name'])[0]
dataset['Energy level'] = pd.factorize(dataset['Energy level'])[0]
dataset['Attention Needs'] = pd.factorize(dataset['Attention Needs'])[0]
dataset['Coat Lenght'] = pd.factorize(dataset['Coat Lenght'])[0]
dataset['Sex'] = pd.factorize(dataset['Sex'])[0]
dataset['Owner Name'] = pd.factorize(dataset['Owner Name'])[0]

"""## Transformăm valorile NaN în valoarea medie în funcție de rasă."""

dataset['Height(cm)'] = dataset.groupby(['Breed Name'])['Height(cm)'].transform(lambda x: x.fillna(x.mean()))

"""## Normalizăm setul de date folosind StandardScaler și MinMaxScaler.

### datasetStandardScaled
"""

datasetStandardScaled = dataset.copy()

columnNames = ['Weight(g)','Height(cm)','Longevity(yrs)']
features = datasetStandardScaled[columnNames]
scaler = StandardScaler().fit(features.values)
features = scaler.transform(features.values)

datasetStandardScaled[columnNames] = features;

"""###datasetMinMaxScaled"""

datasetMinMaxScaled = dataset.copy()

columnNames = ['Weight(g)','Height(cm)','Longevity(yrs)']
features = datasetMinMaxScaled[columnNames]
scaler = MinMaxScaler().fit(features.values)
features = scaler.transform(features.values)

datasetMinMaxScaled[columnNames] = features;

"""## Calculăm corelațiile existente între atributele din setul de date."""

corr = dataset.corr()

sns.heatmap(corr);

plt.figure(figsize=(10, 10))

plt.scatter(dataset['Weight(g)'], dataset['Height(cm)'], marker='o', c=dataset['Breed Name'],
            s=25, edgecolor='k')

plt.xlabel('Weight(g)')
plt.ylabel('Height(g)')

"""## Incărcăm cele 3 seturi de date pe care le vom folosi la antrenare și evaluare.
* X, y, XStandardScale, yStandardScaled, XMinMaxScaled, yMinMaxScaled
"""

X = dataset[['Weight(g)', 'Height(cm)',
       'Energy level', 'Attention Needs']];
y = dataset[['Breed Name']]

XStandardScaled = datasetStandardScaled[['Weight(g)', 'Height(cm)',
       'Energy level', 'Attention Needs']];
yStandardScaled = datasetStandardScaled[['Breed Name']]

XMinMaxScaled = datasetMinMaxScaled[['Weight(g)', 'Height(cm)',
       'Energy level', 'Attention Needs']];
yMinMaxScaled = datasetMinMaxScaled[['Breed Name']]

"""# Prima abordare: învățare automată

## KFold Validation. 

Căutam cei mai buni parametri pentru cei trei algoritmi de învățare. Împărțim setul de intrare în 10 subseturi, fiecare dintre acestea fiind folosit o dată drept set de evaluare pentru algoritmul învățat folosind restul celor 9 seturi.

### Input: 
* Setul de antrenare (X_train, y_train)

### Output:
* cea mai bună acuratețe obținută evaluând unul dintre folduri pentru Logistic Regression, Random Forest și KNN; 
* parametri cu care am obținut acele rezultate de acuratețe pentru fiecare algoritm de învățare 
* tabel cu acuratețile fiecărui fold evaluat în parte pentru cei trei algoritmi de învățare
"""

def kFoldValidationMethod(X_train, y_train):

  kf = KFold(n_splits = 10)

  bestAccuracyLogisticRegression = 0
  bestAccuracyRandomForestClassifier = 0
  bestAccuracyKNNClassifier = 0

  accuracyTable = pd.DataFrame(columns = ['Logistic Regression', 'Random Forest', 'KNN Classifier'])
  for train_index, validation_index in kf.split(X_train):
    modelLogisticRegression = LogisticRegression().fit(X_train.iloc[train_index], y_train.iloc[train_index])
    modelRandomForestClassifier = RandomForestClassifier().fit(X_train.iloc[train_index], y_train.iloc[train_index])
    modelKNNClassifier = KNeighborsClassifier().fit(X_train.iloc[train_index], y_train.iloc[train_index])

    accuracyLogisticRegression = accuracy_score(modelLogisticRegression.predict(X_train.iloc[validation_index]), y_train.iloc[validation_index])
    accuracyRandomForestClassifier = accuracy_score(modelRandomForestClassifier.predict(X_train.iloc[validation_index]), y_train.iloc[validation_index])
    accuracyKNNClassifier = accuracy_score(modelKNNClassifier.predict(X_train.iloc[validation_index]), y_train.iloc[validation_index])

    if accuracyLogisticRegression > bestAccuracyLogisticRegression:
      bestAccuracyLogisticRegression = accuracyLogisticRegression
      paramsLogisticRegression = modelLogisticRegression.get_params()
    if accuracyRandomForestClassifier > bestAccuracyRandomForestClassifier:
      bestAccuracyRandomForestClassifier = accuracyRandomForestClassifier 
      paramsRandomForestClassifier = modelRandomForestClassifier.get_params() 
    if accuracyKNNClassifier > bestAccuracyKNNClassifier:
      bestAccuracyKNNClassifier = accuracyKNNClassifier 
      paramsKNNClassifier = modelKNNClassifier.get_params()  
    
    accuracyTable = accuracyTable.append({'Logistic Regression': accuracyLogisticRegression, 'Random Forest': accuracyRandomForestClassifier, 'KNN Classifier': accuracyKNNClassifier}, ignore_index = True)  

  return (bestAccuracyLogisticRegression, bestAccuracyRandomForestClassifier, bestAccuracyKNNClassifier, paramsLogisticRegression, paramsRandomForestClassifier, paramsKNNClassifier, accuracyTable)

"""### Setul de date fara normalizare.

1) Antrenare
"""

X_train, X_test, y_train, y_test = train_test_split(X,y)
[bestAccuracyLogisticRegression, bestAccuracyRandomForestClassifier, bestAccuracyKNNClassifier, paramsLogisticRegression, paramsRandomForestClassifier, paramsKNNClassifier, accTable] = kFoldValidationMethod(X_train, y_train)

"""2) Analiza scorurilor de acuratețe"""

print ("Valorile maxime obtinute: %lf - Logistic Regression, %lf - Random Forest, %lf - KNN" %(bestAccuracyLogisticRegression, bestAccuracyRandomForestClassifier, bestAccuracyKNNClassifier))
print ("Valorile medii obtinute: %lf - Logistic Regression, %lf - Random Forest, %lf - KNN" %(np.mean(accTable['Logistic Regression']), np.mean(accTable['Random Forest']), np.mean(accTable['KNN Classifier'])))

"""3) Testare"""

accuracyLogisticRegression = accuracy_score(LogisticRegression().fit(X_test, y_test).set_params(**paramsLogisticRegression).predict(X_test), y_test)
accuracyRandomForestClassifier = accuracy_score(RandomForestClassifier().fit(X_test, y_test).set_params(**paramsRandomForestClassifier).predict(X_test), y_test)
accuracyKNNClassifier = accuracy_score(KNeighborsClassifier().fit(X_test, y_test).set_params(**paramsKNNClassifier).predict(X_test), y_test)

print (accuracyLogisticRegression, accuracyRandomForestClassifier, accuracyKNNClassifier)

confusionMatrixLogisticRegression = confusion_matrix(LogisticRegression().fit(X_test, y_test).set_params(**paramsLogisticRegression).predict(X_test), y_test);
confusionMatrixRandomForestClassifier = confusion_matrix(RandomForestClassifier().fit(X_test, y_test).set_params(**paramsRandomForestClassifier).predict(X_test), y_test)
confusionMatrixKNNClassifier = confusion_matrix(KNeighborsClassifier().fit(X_test, y_test).set_params(**paramsKNNClassifier).predict(X_test), y_test)

plt.title("Confusion matrix Logistic Regression");
sns.heatmap(confusionMatrixLogisticRegression, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])
plt.figure()
plt.title("Confusion matrix Random Forest Classifier");
sns.heatmap(confusionMatrixRandomForestClassifier, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])
plt.figure()
plt.title("Confusion matrix KNN Classifier");
sns.heatmap(confusionMatrixKNNClassifier, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])

"""### Setul de date cu StandardScaler

1) Antrenare
"""

X_train, X_test, y_train, y_test = train_test_split(XStandardScaled,yStandardScaled)

[bestAccuracyLogisticRegression, bestAccuracyRandomForestClassifier, bestAccuracyKNNClassifier, paramsLogisticRegression, paramsRandomForestClassifier, paramsKNNClassifier, accTable] = kFoldValidationMethod(X_train, y_train)

"""2) Analiza scorurilor de acuratețe"""

print ("Valorile maxime obtinute: %lf - Logistic Regression, %lf - Random Forest, %lf - KNN" %(bestAccuracyLogisticRegression, bestAccuracyRandomForestClassifier, bestAccuracyKNNClassifier))
print ("Valorile medii obtinute: %lf - Logistic Regression, %lf - Random Forest, %lf - KNN" %(np.mean(accTable['Logistic Regression']), np.mean(accTable['Random Forest']), np.mean(accTable['KNN Classifier'])))

"""3) Testare"""

accuracyLogisticRegression = accuracy_score(LogisticRegression().fit(X_test, y_test).set_params(**paramsLogisticRegression).predict(X_test), y_test)
accuracyRandomForestClassifier = accuracy_score(RandomForestClassifier().fit(X_test, y_test).set_params(**paramsRandomForestClassifier).predict(X_test), y_test)
accuracyKNNClassifier = accuracy_score(KNeighborsClassifier().fit(X_test, y_test).set_params(**paramsKNNClassifier).predict(X_test), y_test)

print (accuracyLogisticRegression, accuracyRandomForestClassifier, accuracyKNNClassifier)

confusionMatrixLogisticRegression = confusion_matrix(LogisticRegression().fit(X_test, y_test).set_params(**paramsLogisticRegression).predict(X_test), y_test);
confusionMatrixRandomForestClassifier = confusion_matrix(RandomForestClassifier().fit(X_test, y_test).set_params(**paramsRandomForestClassifier).predict(X_test), y_test)
confusionMatrixKNNClassifier = confusion_matrix(KNeighborsClassifier().fit(X_test, y_test).set_params(**paramsKNNClassifier).predict(X_test), y_test)

plt.title("Confusion matrix Logistic Regression");
sns.heatmap(confusionMatrixLogisticRegression, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])
plt.figure()
plt.title("Confusion matrix Random Forest Classifier");
sns.heatmap(confusionMatrixRandomForestClassifier, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])
plt.figure()
plt.title("Confusion matrix KNN Classifier");
sns.heatmap(confusionMatrixKNNClassifier, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])

"""### Setul de date cu MinMaxScaler

1) Antrenare
"""

X_train, X_test, y_train, y_test = train_test_split(XMinMaxScaled,yMinMaxScaled)

[bestAccuracyLogisticRegression, bestAccuracyRandomForestClassifier, bestAccuracyKNNClassifier, paramsLogisticRegression, paramsRandomForestClassifier, paramsKNNClassifier, accTable] = kFoldValidationMethod(X_train, y_train)

"""2) Analiza scorurilor de acuratețe"""

print ("Valorile maxime obtinute: %lf - Logistic Regression, %lf - Random Forest, %lf - KNN" %(bestAccuracyLogisticRegression, bestAccuracyRandomForestClassifier, bestAccuracyKNNClassifier))
print ("Valorile medii obtinute: %lf - Logistic Regression, %lf - Random Forest, %lf - KNN" %(np.mean(accTable['Logistic Regression']), np.mean(accTable['Random Forest']), np.mean(accTable['KNN Classifier'])))

"""3) Testare"""

accuracyLogisticRegression = accuracy_score(LogisticRegression().fit(X_test, y_test).set_params(**paramsLogisticRegression).predict(X_test), y_test)
accuracyRandomForestClassifier = accuracy_score(RandomForestClassifier().fit(X_test, y_test).set_params(**paramsRandomForestClassifier).predict(X_test), y_test)
accuracyKNNClassifier = accuracy_score(KNeighborsClassifier().fit(X_test, y_test).set_params(**paramsKNNClassifier).predict(X_test), y_test)

print (accuracyLogisticRegression, accuracyRandomForestClassifier, accuracyKNNClassifier)

confusionMatrixLogisticRegression = confusion_matrix(LogisticRegression().fit(X_test, y_test).set_params(**paramsLogisticRegression).predict(X_test), y_test);
confusionMatrixRandomForestClassifier = confusion_matrix(RandomForestClassifier().fit(X_test, y_test).set_params(**paramsRandomForestClassifier).predict(X_test), y_test)
confusionMatrixKNNClassifier = confusion_matrix(KNeighborsClassifier().fit(X_test, y_test).set_params(**paramsKNNClassifier).predict(X_test), y_test)

plt.title("Confusion matrix Logistic Regression");
sns.heatmap(confusionMatrixLogisticRegression, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])
plt.figure()
plt.title("Confusion matrix Random Forest Classifier");
sns.heatmap(confusionMatrixRandomForestClassifier, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])
plt.figure()
plt.title("Confusion matrix KNN Classifier");
sns.heatmap(confusionMatrixKNNClassifier, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])

"""# A doua abordare: învățare din interpretări"""

!pip install problog

from problog.program import PrologString
from problog.core import ProbLog
from problog import get_evaluatable
from sklearn.model_selection import train_test_split
from problog.logic import Term
from problog.program import PrologString
from problog.learning import lfi
from problog.tasks import sample
from problog.program import SimpleProgram
from problog.logic import Constant,Var,Term,AnnotatedDisjunction

"""Vom păstra aceeași problema și anume prezicerea rasei cățelului, dar vom folosi drept atribute pe baza cărora prezicem eticheta doar înălțimea și greutatea. 

Setul de date va fi împărțit aleator în două subseturi precum în abordarea anterioară: setul de antrenare și setul de testare.
"""

dataset = pd.read_csv('dataset.csv', delimiter=",")
X = dataset[['Weight(g)', 'Height(cm)']];
y = dataset[['Breed Name']]

X_train, X_test, y_train, y_test = train_test_split(X,y)

"""După care, pentru fiecare rasă în parte am construit un program în ProbLog pentru care am considerat drept fapte probabiliste toate combinațiile de înălțime/greutate plus o constantă (una dintre categoriile în care se pot clasa).

Pentru fiecare rasă am construit un set cu interpretari doar pe baza exemplelor din rasa respectivă pentru ca probabilitățile învățate sa fie caracteristice numai și numai acelui tip de cățel. 

Cazul analizat a presupus observabilitate totală asupra lumii analizate, adică pentru toate faptele probabiliste am cunoscut valoarea de adevăr în fiecare interpretare.

## Amstaff
"""

p_amstaff = PrologString("""

t(_)::weight(low).
t(_)::weight(medium).
t(_)::weight(high).

t(_)::height(low).
t(_)::height(medium).
t(_)::height(high).

""")

interpretari_amstaff = []

for index, row in X_train.iterrows():
  # print (row["Breed Name"])
  sample_curent = []
  if row["Weight(g)"] > 30000:
    weight_curr = 'high'
    sample_curent.append((Term('weight', Term('high')), True))
    sample_curent.append((Term('weight', Term('medium')), False))
    sample_curent.append((Term('weight', Term('low')), False))                                        
  elif row["Weight(g)"] > 20000:
    weight_curr = 'medium'
    sample_curent.append((Term('weight', Term('high')), False))
    sample_curent.append((Term('weight', Term('medium')), True))
    sample_curent.append((Term('weight', Term('low')), False))
  else:
    weight_curr = 'low'                                    
    sample_curent.append((Term('weight', Term('high')), False))
    sample_curent.append((Term('weight', Term('medium')), False))
    sample_curent.append((Term('weight', Term('low')), True))
  
  if row["Height(cm)"] > 60:
    height_curr = 'high'                                     
    sample_curent.append((Term('height', Term('high')), True))
    sample_curent.append((Term('height', Term('medium')), False))
    sample_curent.append((Term('height', Term('low')), False))                                        
  elif row["Height(cm)"] > 37:
    height_curr = 'medium'
    sample_curent.append((Term('height', Term('high')), False))
    sample_curent.append((Term('height', Term('medium')), True))
    sample_curent.append((Term('height', Term('low')), False))
  else:
    height_curr = 'low'                                  
    sample_curent.append((Term('height', Term('high')), False))
    sample_curent.append((Term('height', Term('medium')), False))
    sample_curent.append((Term('height', Term('low')), True))
  
  if y_train["Breed Name"][index].lower().replace(" ", "") == 'amstaff':
    interpretari_amstaff.append(sample_curent)

score, weights, atoms, iteration, lfi_problem = lfi.run_lfi(p_amstaff, interpretari_amstaff)

print (lfi_problem.get_model())

p_amstaff = PrologString('''
  0.059459459459459::weight(low).
  0.783783783783784::weight(medium).
  0.156756756756757::weight(high).
  0.0::height(low).
  1.0::height(medium).
  0.0::height(high).
  
  amstaff(C,D) :- weight(C), height(D).

  query(amstaff(A,B)).
''')

dict_amstaff = get_evaluatable().create_from(p_amstaff).evaluate()

"""## Pug"""

p_pug = PrologString("""

t(_)::weight(low).
t(_)::weight(medium).
t(_)::weight(high).

t(_)::height(low).
t(_)::height(medium).
t(_)::height(high).

""")

interpretari_pug = []

for index, row in X_train.iterrows():
  # print (row["Breed Name"])
  sample_curent = []
  if row["Weight(g)"] > 30000:
    weight_curr = 'high'
    sample_curent.append((Term('weight', Term('high')), True))
    sample_curent.append((Term('weight', Term('medium')), False))
    sample_curent.append((Term('weight', Term('low')), False))                                        
  elif row["Weight(g)"] > 20000:
    weight_curr = 'medium'
    sample_curent.append((Term('weight', Term('high')), False))
    sample_curent.append((Term('weight', Term('medium')), True))
    sample_curent.append((Term('weight', Term('low')), False))
  else:
    weight_curr = 'low'                                    
    sample_curent.append((Term('weight', Term('high')), False))
    sample_curent.append((Term('weight', Term('medium')), False))
    sample_curent.append((Term('weight', Term('low')), True))
  
  if row["Height(cm)"] > 60:
    height_curr = 'high'                                     
    sample_curent.append((Term('height', Term('high')), True))
    sample_curent.append((Term('height', Term('medium')), False))
    sample_curent.append((Term('height', Term('low')), False))                                        
  elif row["Height(cm)"] > 37:
    height_curr = 'medium'
    sample_curent.append((Term('height', Term('high')), False))
    sample_curent.append((Term('height', Term('medium')), True))
    sample_curent.append((Term('height', Term('low')), False))
  else:
    height_curr = 'low'                                  
    sample_curent.append((Term('height', Term('high')), False))
    sample_curent.append((Term('height', Term('medium')), False))
    sample_curent.append((Term('height', Term('low')), True))
  
  if y_train["Breed Name"][index].lower().replace(" ", "") == 'pug':
    interpretari_pug.append(sample_curent)

score, weights, atoms, iteration, lfi_problem = lfi.run_lfi(p_pug, interpretari_pug)

print (lfi_problem.get_model())

p_pug = PrologString('''
  1.0::weight(low).
  0.0::weight(medium).
  0.0::weight(high).
  0.868131868131868::height(low).
  0.131868131868132::height(medium).
  0.0::height(high).
  
  pug(C,D) :- weight(C), height(D).

  query(pug(A,B)).
''')

dict_pug = get_evaluatable().create_from(p_pug).evaluate()

"""## Jack Russel Terrier"""

p_jackrusselterrier = PrologString("""

t(_)::weight(low).
t(_)::weight(medium).
t(_)::weight(high).

t(_)::height(low).
t(_)::height(medium).
t(_)::height(high).

""")

interpretari_jackrusselterrier = []

for index, row in X_train.iterrows():
  # print (row["Breed Name"])
  sample_curent = []
  if row["Weight(g)"] > 30000:
    weight_curr = 'high'
    sample_curent.append((Term('weight', Term('high')), True))
    sample_curent.append((Term('weight', Term('medium')), False))
    sample_curent.append((Term('weight', Term('low')), False))                                        
  elif row["Weight(g)"] > 20000:
    weight_curr = 'medium'
    sample_curent.append((Term('weight', Term('high')), False))
    sample_curent.append((Term('weight', Term('medium')), True))
    sample_curent.append((Term('weight', Term('low')), False))
  else:
    weight_curr = 'low'                                    
    sample_curent.append((Term('weight', Term('high')), False))
    sample_curent.append((Term('weight', Term('medium')), False))
    sample_curent.append((Term('weight', Term('low')), True))
  
  if row["Height(cm)"] > 60:
    height_curr = 'high'                                     
    sample_curent.append((Term('height', Term('high')), True))
    sample_curent.append((Term('height', Term('medium')), False))
    sample_curent.append((Term('height', Term('low')), False))                                        
  elif row["Height(cm)"] > 37:
    height_curr = 'medium'
    sample_curent.append((Term('height', Term('high')), False))
    sample_curent.append((Term('height', Term('medium')), True))
    sample_curent.append((Term('height', Term('low')), False))
  else:
    height_curr = 'low'                                  
    sample_curent.append((Term('height', Term('high')), False))
    sample_curent.append((Term('height', Term('medium')), False))
    sample_curent.append((Term('height', Term('low')), True))
  
  if y_train["Breed Name"][index].lower().replace(" ", "") == 'jackrusselterrier':
    interpretari_jackrusselterrier.append(sample_curent)

score, weights, atoms, iteration, lfi_problem = lfi.run_lfi(p_jackrusselterrier, interpretari_jackrusselterrier)

print (lfi_problem.get_model())

p_jackrusselterrier = PrologString('''
  1.0::weight(low).
  0.0::weight(medium).
  0.0::weight(high).
  1.0::height(low).
  0.0::height(medium).
  0.0::height(high).
  
  jackrusselterrier(C,D) :- weight(C), height(D).

  query(jackrusselterrier(A,B)).
''')

dict_jackrusselterrier = get_evaluatable().create_from(p_jackrusselterrier).evaluate()

"""## Bloodhound"""

p_bloodhound = PrologString("""

t(_)::weight(low).
t(_)::weight(medium).
t(_)::weight(high).

t(_)::height(low).
t(_)::height(medium).
t(_)::height(high).

""")

interpretari_bloodhound = []

for index, row in X_train.iterrows():
  # print (row["Breed Name"])
  sample_curent = []
  if row["Weight(g)"] > 30000:
    weight_curr = 'high'
    sample_curent.append((Term('weight', Term('high')), True))
    sample_curent.append((Term('weight', Term('medium')), False))
    sample_curent.append((Term('weight', Term('low')), False))                                        
  elif row["Weight(g)"] > 15000:
    weight_curr = 'medium'
    sample_curent.append((Term('weight', Term('high')), False))
    sample_curent.append((Term('weight', Term('medium')), True))
    sample_curent.append((Term('weight', Term('low')), False))
  else:
    weight_curr = 'low'                                    
    sample_curent.append((Term('weight', Term('high')), False))
    sample_curent.append((Term('weight', Term('medium')), False))
    sample_curent.append((Term('weight', Term('low')), True))
  
  if row["Height(cm)"] > 60:
    height_curr = 'high'                                     
    sample_curent.append((Term('height', Term('high')), True))
    sample_curent.append((Term('height', Term('medium')), False))
    sample_curent.append((Term('height', Term('low')), False))                                        
  elif row["Height(cm)"] > 37:
    height_curr = 'medium'
    sample_curent.append((Term('height', Term('high')), False))
    sample_curent.append((Term('height', Term('medium')), True))
    sample_curent.append((Term('height', Term('low')), False))
  else:
    height_curr = 'low'                                  
    sample_curent.append((Term('height', Term('high')), False))
    sample_curent.append((Term('height', Term('medium')), False))
    sample_curent.append((Term('height', Term('low')), True))
  
  if y_train["Breed Name"][index].lower().replace(" ", "") == 'bloodhound':
    interpretari_bloodhound.append(sample_curent)

score, weights, atoms, iteration, lfi_problem = lfi.run_lfi(p_bloodhound, interpretari_bloodhound)

print (lfi_problem.get_model())

p_bloodhound = PrologString('''
  0.0::weight(low).
  0.005917159763314::weight(medium).
  0.994082840236686::weight(high).
  0.0::height(low).
  0.0::height(medium).
  1.0::height(high).

  
  bloodhound(C,D) :- weight(C), height(D).

  query(bloodhound(A,B)).
''')

dict_bloodhound = get_evaluatable().create_from(p_bloodhound).evaluate()

"""### Dictionarele pentru: Amstaff, Pug, Jack RusselTerrier, Bloodhound"""

print (dict_amstaff)
print (dict_pug)
print (dict_jackrusselterrier)
print (dict_bloodhound)

"""## Predicții pentru setul de testare

După ce am construit modelele pentru toate cele patru rase existente, vom parcurge setul de testare
pentru a calcula probabilitățile pentru fiecare exemplu în parte ca pe baza înălțimii și a greutății sale sa corespunda tuturor celor 4 rase posibile. Aflate aceste patru probabilități, o vom alege pe cea mai mare și o vom compara cu eticheta adevărată a exemplului respectiv.
"""

exemple_corecte = 0
exemple_totale = 0

y_prezis = []
for index, row in X_test.iterrows():
  if row["Weight(g)"] > 30000:
    weight_curr = 'high'
  elif row["Weight(g)"] > 15000:
    weight_curr = 'medium'
  else:
    weight_curr = 'low'   
  
  if row["Height(cm)"] > 60:
    height_curr = 'high'                                     
  elif row["Height(cm)"] > 37:
    height_curr = 'medium'
  else:
    height_curr = 'low'
    
  prob_amstaff = dict_amstaff[Term('amstaff', Term(weight_curr), Term(height_curr))]
  prob_pug = dict_pug[Term('pug', Term(weight_curr), Term(height_curr))]
  prob_bloodhound = dict_bloodhound[Term('bloodhound', Term(weight_curr), Term(height_curr))]
  prob_jackrusselterrier = dict_jackrusselterrier[Term('jackrusselterrier', Term(weight_curr), Term(height_curr))]
  
  if prob_amstaff > prob_pug and prob_amstaff > prob_bloodhound and prob_amstaff > prob_jackrusselterrier:
    eticheta = 'Amstaff'
  elif prob_pug > prob_amstaff and prob_pug > prob_bloodhound and prob_pug > prob_jackrusselterrier:
    eticheta = 'Pug'  
  elif prob_bloodhound > prob_pug and prob_bloodhound > prob_amstaff and prob_bloodhound > prob_jackrusselterrier:
    eticheta = 'Bloodhound'  
  elif prob_jackrusselterrier > prob_pug and prob_jackrusselterrier > prob_amstaff and prob_jackrusselterrier > prob_bloodhound:
    eticheta = 'Jack Russel Terrier'
  
  y_prezis.append(eticheta)
  print (eticheta, y_test["Breed Name"][index])
  if eticheta == y_test["Breed Name"][index]:
    exemple_corecte = exemple_corecte + 1
  exemple_totale = exemple_totale + 1

print ("Dintre cele %lf exemple ale multimii de test au fost clasificate corect %lf exemple; adica %lf la suta " %(exemple_corecte, exemple_totale, exemple_corecte*100/exemple_totale))

confusionMatrixLogisticRegression = confusion_matrix(y_prezis, y_test);
plt.title("Confusion matrix Logistic Regression");
sns.heatmap(confusionMatrixLogisticRegression, annot=True, xticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'], yticklabels=['Amstaff', 'Bloodhound', 'Pug', 'Jack Russel Terrier'])
plt.figure()